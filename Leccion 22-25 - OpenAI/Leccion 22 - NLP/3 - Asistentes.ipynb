{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de40bb2",
   "metadata": {},
   "source": [
    "# 3 - Asistentes\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/openai_assistants.webp\" style=\"width:400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2677071",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---¿Qué-es-un-asistente?\" data-toc-modified-id=\"1---¿Qué-es-un-asistente?-1\">1 - ¿Qué es un asistente?</a></span></li><li><span><a href=\"#2---¿Cómo-crear-un-asistente?\" data-toc-modified-id=\"2---¿Cómo-crear-un-asistente?-2\">2 - ¿Cómo crear un asistente?</a></span></li><li><span><a href=\"#3---Threads-(Hilos)\" data-toc-modified-id=\"3---Threads-(Hilos)-3\">3 - Threads (Hilos)</a></span></li><li><span><a href=\"#4---Runs-(Ejecuciones)\" data-toc-modified-id=\"4---Runs-(Ejecuciones)-4\">4 - Runs (Ejecuciones)</a></span></li><li><span><a href=\"#5---Mensajes\" data-toc-modified-id=\"5---Mensajes-5\">5 - Mensajes</a></span></li><li><span><a href=\"#6---Tools\" data-toc-modified-id=\"6---Tools-6\">6 - Tools</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1---Code-Interpreter\" data-toc-modified-id=\"6.1---Code-Interpreter-6.1\">6.1 - Code Interpreter</a></span></li><li><span><a href=\"#6.2---Steps-(Pasos)\" data-toc-modified-id=\"6.2---Steps-(Pasos)-6.2\">6.2 - Steps (Pasos)</a></span></li><li><span><a href=\"#6.3---Retrieval-(Recuperación)\" data-toc-modified-id=\"6.3---Retrieval-(Recuperación)-6.3\">6.3 - Retrieval (Recuperación)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164f5a1",
   "metadata": {},
   "source": [
    "## 1 - ¿Qué es un asistente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889882c7",
   "metadata": {},
   "source": [
    "Un asistente de OpenAI es un sistema de inteligencia artificial diseñado para interactuar con los usuarios a través de texto, proporcionando respuestas útiles, relevantes y contextuales a las preguntas o solicitudes planteadas. Estos asistentes utilizan modelos avanzados de lenguaje natural, como GPT-3.5, GPT-4 o GPT-4o, para comprender y generar texto de manera coherente y precisa. \n",
    "\n",
    "\n",
    "**Características de un asistente de OpenAI**\n",
    "\n",
    "\n",
    "1. Comprensión del lenguaje natural: Los asistentes de OpenAI pueden interpretar y comprender el lenguaje humano de forma natural, permitiendo interacciones fluidas y efectivas.\n",
    "\n",
    "\n",
    "2. Generación de texto: Pueden generar texto en función de las entradas del usuario, ya sea para responder preguntas, proporcionar explicaciones, generar ideas o escribir artículos.\n",
    "\n",
    "\n",
    "3. Multimodalidad: Algunos modelos, como GPT-4o, son multimodales, lo que significa que pueden aceptar y procesar tanto texto como imágenes y generar texto como respuesta.\n",
    "\n",
    "\n",
    "4. Soporte multilingüe: Los asistentes pueden entender y generar texto en múltiples idiomas, lo que los hace útiles para una audiencia global.\n",
    "\n",
    "\n",
    "5. Aplicaciones diversas: Se pueden utilizar en una amplia variedad de aplicaciones, incluyendo asistencia virtual, generación de contenido, tutoría educativa y atención al cliente.\n",
    "\n",
    "\n",
    "6. Interacción en tiempo real: Los asistentes pueden proporcionar respuestas en tiempo real, lo que es ideal para aplicaciones de chat y soporte en vivo.\n",
    "\n",
    "\n",
    "7. Optimización para conversaciones: Modelos como GPT-3.5 Turbo y GPT-4 están optimizados para conversaciones, ofreciendo respuestas más naturales y contextuales en interacciones de chat.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Ejemplos de Uso de un Asistente de OpenAI**\n",
    "\n",
    "\n",
    "1. Asistencia virtual: Los asistentes pueden actuar como chatbots que ayudan a los usuarios con consultas generales, reservas o compras en línea.\n",
    "\n",
    "\n",
    "2. Generación de contenido: Pueden ayudar a redactar artículos, informes, correos electrónicos y otros tipos de contenido escrito.\n",
    "\n",
    "\n",
    "3. Educación y tutoría: Los asistentes pueden proporcionar explicaciones sobre diversos temas, responder preguntas educativas y ayudar con las tareas escolares.\n",
    "\n",
    "\n",
    "4. Atención al cliente: Pueden manejar consultas de clientes, proporcionar soporte técnico y resolver problemas de manera eficiente.\n",
    "\n",
    "\n",
    "5. Traducción y localización: Los asistentes pueden traducir texto entre varios idiomas y ayudar en la localización de contenido para diferentes regiones.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Cómo Funciona un Asistente de OpenAI**\n",
    "\n",
    "\n",
    "1. Entrada del usuario: El usuario proporciona una entrada de texto y en algunos casos, imágenes.\n",
    "\n",
    "\n",
    "2. Procesamiento por el modelo: El modelo de lenguaje de OpenAI procesa la entrada, utilizando su entrenamiento en una vasta cantidad de datos para comprender y generar una respuesta apropiada.\n",
    "\n",
    "\n",
    "3. Generación de respuesta: El modelo genera una respuesta en función de la entrada del usuario y el contexto de la conversación.\n",
    "\n",
    "\n",
    "4. Entrega de la respuesta: La respuesta generada se entrega al usuario a través de la interfaz del asistente, completando la interacción.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**API de Completaciones de Chat vs API de Asistentes**\n",
    "\n",
    "Las primitivas de la API de Completaciones de Chat son los mensajes, sobre los cuales realizas una Completion con un modelo, gpt-3.5-turbo, gpt-4 o gpt-4o. Es ligera y poderosa, pero inherentemente sin estado, lo que significa que debemos gestionar manualmente el estado de la conversación, las definiciones de herramientas, los documentos de recuperación y la ejecución de código.\n",
    "\n",
    "Las primitivas de la API de Asistentes son:\n",
    "\n",
    "+ **Assistants (Asistentes)**: Encapsulan un modelo base, instrucciones, herramientas y documentos de contexto.\n",
    "\n",
    "+ **Threads (Hilos)**: Representan el estado de una conversación.\n",
    "\n",
    "+ **Runs (Ejecuciones)**: Impulsan la ejecución de un asistente en un Thread, incluyendo respuestas textuales y uso de herramientas en varios pasos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebb2c3",
   "metadata": {},
   "source": [
    "## 2 - ¿Cómo crear un asistente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0fe56f",
   "metadata": {},
   "source": [
    "La forma más fácil de comenzar con la API de asistentes es a través del [Assistants Playground](https://platform.openai.com/playground). Tenemos toda la documentación [aquí](https://platform.openai.com/docs/assistants/overview).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/assistants_overview_assistants_playground.png\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbe3eb",
   "metadata": {},
   "source": [
    "Vamos a crear un asistente \"Tutor en Matemáticas\" desde el playground de la página de OpenAI. Le damos un nombre, unas instrucciones iniciales y seleccionamos el modelo que va a usar el asistente.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/assistants_overview_new_assistant.png\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de409bb",
   "metadata": {},
   "source": [
    "Podemos ver los asistentes que hemos creado en el [Assistants Dashboard](https://platform.openai.com/assistants).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/assistants_overview_assistants_dashboard.png\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdce397",
   "metadata": {},
   "source": [
    "Podemos crear nuestro asistente a través de código, veamos cómo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98111bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerías, API KEY e iniciamos cliente\n",
    "\n",
    "import os                           \n",
    "from dotenv import load_dotenv \n",
    "import openai as ai\n",
    "import json\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "cliente = ai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8d6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el asistente\n",
    "\n",
    "asistente = cliente.beta.assistants.create(name='Tutor de matemáticas',\n",
    "                                           instructions='''Eres un tutor personal de matemáticas. \n",
    "                                                        Responde preguntas brevemente, en una frase o menos.''',\n",
    "                                           model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169210b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_z9Eh9aRkMocFmM2wr0J8Y8x9',\n",
       " 'created_at': 1730796350,\n",
       " 'description': None,\n",
       " 'instructions': 'Eres un tutor personal de matemáticas. \\n                                                        Responde preguntas brevemente, en una frase o menos.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'name': 'Tutor de matemáticas',\n",
       " 'object': 'assistant',\n",
       " 'tools': [],\n",
       " 'response_format': 'auto',\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': None, 'file_search': None},\n",
       " 'top_p': 1.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos su descripción\n",
    "\n",
    "json.loads(asistente.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364ff3e",
   "metadata": {},
   "source": [
    "Independientemente de si creamos el asistente a través del Dashboard o con la API, querremos mantener un registro del ID del asistente. Este es el identificador que utilizaremos para referirnos al asistente a lo largo de los hilos y ejecuciones.\n",
    "\n",
    "A continuación, crearemos un nuevo hilo y añadiremos un mensaje a este. Esto mantendrá el estado de nuestra conversación, por lo que no tendremos que volver a enviar todo el historial de mensajes cada vez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51d524",
   "metadata": {},
   "source": [
    "## 3 - Threads (Hilos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0d7d",
   "metadata": {},
   "source": [
    "Un Thread (Hilo) representa el estado de una conversación continua. Los hilos son utilizados para mantener la continuidad y el contexto de las interacciones con el asistente, permitiendo que la conversación progrese sin necesidad de reenviar todo el historial de mensajes en cada solicitud. \n",
    "\n",
    "\n",
    "**Características de un thread**\n",
    "\n",
    "1. Persistencia del estado: Los hilos almacenan el estado de la conversación, lo que permite que el Asistente recuerde los mensajes anteriores y responda de manera coherente y contextual.\n",
    "\n",
    "\n",
    "2. Gestión del contexto: Un hilo puede contener múltiples mensajes, cada uno de los cuales contribuye al contexto general de la conversación. Esto facilita interacciones más naturales y fluidas.\n",
    "\n",
    "\n",
    "3. Identificación única: Cada hilo tiene un identificador único que se utiliza para referirse a él durante las interacciones con la API. Esto asegura que las respuestas se mantengan consistentes dentro del contexto de ese hilo específico.\n",
    "\n",
    "\n",
    "4. Soporte para ejecuciones múltiples: Un hilo puede manejar múltiples Runs (Ejecuciones), lo que permite el uso de herramientas y la generación de respuestas en varios pasos dentro de la misma conversación.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Ejemplo de uso de un Thread**\n",
    "\n",
    "\n",
    "1. Crear un nuevo Thread: Iniciamos un nuevo hilo para una conversación específica.\n",
    "\n",
    "\n",
    "2. Agregar mensajes al Thread: Añadimos mensajes al hilo a medida que progresa la conversación. Estos mensajes pueden ser preguntas del usuario o respuestas del asistente.\n",
    "\n",
    "\n",
    "3. Mantener el contexto: Utilizas el hilo para mantener el contexto de la conversación, de modo que el asistente pueda proporcionar respuestas más relevantes basadas en la historia del hilo.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Beneficios de usar Threads**\n",
    "\n",
    "\n",
    "1. Continuidad en conversaciones largas: Ideal para aplicaciones donde la conversación se extiende a lo largo de varias interacciones, como en tutorías, atención al cliente o asesoramiento personalizado.\n",
    "\n",
    "\n",
    "2. Eficiencia: Reduce la necesidad de enviar repetidamente el historial completo de mensajes, mejorando la eficiencia y reduciendo la latencia.\n",
    "\n",
    "\n",
    "3. Experiencia de usuario mejorada: Proporciona una experiencia de usuario más coherente y fluida, ya que el asistente puede recordar y hacer referencia a interacciones pasadas dentro del mismo hilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72eb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el hilo\n",
    "\n",
    "thread = cliente.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d12f3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_PxT3DGYiI7pY9KXnfCSDHGpn',\n",
       " 'created_at': 1730796350,\n",
       " 'metadata': {},\n",
       " 'object': 'thread',\n",
       " 'tool_resources': {'code_interpreter': None, 'file_search': None}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos su descripción\n",
    "\n",
    "json.loads(thread.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dedcfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora añadimos un mensaje al hilo\n",
    "\n",
    "mensaje = cliente.beta.threads.messages.create(thread_id=thread.id,\n",
    "                                               role='user',\n",
    "                                               content='¿Puedes resolver la ecuación `3x + 11 = 14`?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ef3dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_UYOayEjSRvFHOozocZ2jZkix',\n",
       " 'assistant_id': None,\n",
       " 'attachments': [],\n",
       " 'completed_at': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': '¿Puedes resolver la ecuación `3x + 11 = 14`?'},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1730796351,\n",
       " 'incomplete_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'status': None,\n",
       " 'thread_id': 'thread_PxT3DGYiI7pY9KXnfCSDHGpn'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos su descripción\n",
    "\n",
    "json.loads(mensaje.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0d9ab",
   "metadata": {},
   "source": [
    "## 4 - Runs (Ejecuciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb832f",
   "metadata": {},
   "source": [
    "Un Run (Ejecución) es un proceso que permite al asistente interactuar dentro de un hilo. Cada ejecución representa una instancia de procesamiento donde el asistente analiza la conversación actual y genera una respuesta. \n",
    "\n",
    "\n",
    "**Características de un Run**\n",
    "\n",
    "\n",
    "1. Procesamiento de mensajes: Un Run toma los mensajes en el hilo y los procesa para generar una respuesta adecuada. Esto incluye analizar el contexto proporcionado por el historial de mensajes.\n",
    "\n",
    "\n",
    "2. Interacción con herramientas: Durante un Run, el asistente puede utilizar herramientas definidas, como funciones específicas o acceso a bases de datos, para proporcionar respuestas más precisas o realizar tareas complejas.\n",
    "\n",
    "\n",
    "3. Generación de respuestas: Al final de un Run, el asistente genera una respuesta que se añade al hilo, manteniendo el contexto de la conversación.\n",
    "\n",
    "\n",
    "4. Multi-Paso: Un Run puede involucrar múltiples pasos, utilizando varias herramientas y generando respuestas intermedias antes de llegar a una conclusión final.\n",
    "\n",
    "\n",
    "5. Costo por tokens: Aunque no necesitas enviar todo el historial de mensajes en cada solicitud, se te cobrará por los tokens de todo el historial de la conversación en cada Run.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Ejemplo de Uso de un Run**\n",
    "\n",
    "\n",
    "1. Iniciar un Run: Cuando un usuario envía una nueva entrada en una conversación activa, se inicia un Run para procesar esta entrada.\n",
    "\n",
    "\n",
    "2. Procesar la entrada: El asistente revisa el historial del hilo y utiliza cualquier herramienta necesaria para procesar la nueva entrada del usuario.\n",
    "\n",
    "\n",
    "3. Generar respuesta: El asistente genera una respuesta basada en la entrada actual y el contexto del hilo.\n",
    "\n",
    "\n",
    "4. Actualizar el hilo: La respuesta se añade al hilo, actualizando el estado de la conversación.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Beneficios de usar Runs**\n",
    "\n",
    "\n",
    "1. Gestión del contexto: Los Runs permiten al asistente mantener y utilizar el contexto completo de la conversación, proporcionando respuestas más coherentes y precisas.\n",
    "\n",
    "\n",
    "2. Uso eficiente de herramientas: Facilitan el uso de herramientas y funciones definidas, permitiendo al asistente realizar tareas complejas y acceder a datos externos.\n",
    "\n",
    "\n",
    "3. Experiencia de usuario mejorada: Al mantener el estado de la conversación y utilizar herramientas eficientemente, los Runs mejoran la calidad y relevancia de las respuestas del asistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37aff42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una ejecución\n",
    "\n",
    "run = cliente.beta.threads.runs.create(thread_id=thread.id,\n",
    "                                       assistant_id=asistente.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac76b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_c5ay1bPff8AoiYfBvDARX8H5',\n",
       " 'assistant_id': 'asst_z9Eh9aRkMocFmM2wr0J8Y8x9',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1730796351,\n",
       " 'expires_at': 1730796951,\n",
       " 'failed_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': 'Eres un tutor personal de matemáticas. \\n                                                        Responde preguntas brevemente, en una frase o menos.',\n",
       " 'last_error': None,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'object': 'thread.run',\n",
       " 'parallel_tool_calls': True,\n",
       " 'required_action': None,\n",
       " 'response_format': 'auto',\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_PxT3DGYiI7pY9KXnfCSDHGpn',\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'truncation_strategy': {'type': 'auto', 'last_messages': None},\n",
       " 'usage': None,\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'tool_resources': {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos su descripción\n",
    "\n",
    "json.loads(run.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e5bd7",
   "metadata": {},
   "source": [
    "A diferencia de crear una completación en la API de Completaciones de Chat, crear una Ejecución (Run) es una operación asíncrona. Devolverá inmediatamente los metadatos de la Ejecución, que incluyen un `status` (estado) que inicialmente estará configurado en `queued` (en cola). El status se actualizará a medida que el asistente realice operaciones, como usar herramientas y agregar mensajes.\n",
    "\n",
    "Para saber cuándo el asistente ha completado el procesamiento, podemos consultar el estado de la ejecución en un bucle. Aunque aquí solo estamos verificando si el estado es `queued` (en cola) o `in_progress` (en progreso), en la práctica una Ejecución puede experimentar una [variedad de cambios de estado](https://platform.openai.com/docs/api-reference/runs/object#runs/object-status) que podemos elegir mostrar al usuario. Estos se llaman Steps, y se cubrirán más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d417870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos time para manejo temporal\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289dfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos función para espera de la respuesta\n",
    "\n",
    "def esperar_ejecucion(run: object, thread: object) -> object:\n",
    "    \n",
    "    \"\"\"\n",
    "    Esta función espera a que se complete la ejecución\n",
    "    revisando el status.\n",
    "    \n",
    "    Params:\n",
    "    run: openai.types.beta.threads.run.Run, ejecución\n",
    "    thread: openai.types.beta.thread.Thread, hilo\n",
    "    \n",
    "    Return:\n",
    "    run: openai.types.beta.threads.run.Run, ejecución completada\n",
    "    \"\"\"\n",
    "    \n",
    "    while run.status == 'queued' or run.status == 'in_progress':\n",
    "        \n",
    "        run = cliente.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75d4d066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_c5ay1bPff8AoiYfBvDARX8H5',\n",
       " 'assistant_id': 'asst_z9Eh9aRkMocFmM2wr0J8Y8x9',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1730796353,\n",
       " 'created_at': 1730796351,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': 'Eres un tutor personal de matemáticas. \\n                                                        Responde preguntas brevemente, en una frase o menos.',\n",
       " 'last_error': None,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'object': 'thread.run',\n",
       " 'parallel_tool_calls': True,\n",
       " 'required_action': None,\n",
       " 'response_format': 'auto',\n",
       " 'started_at': 1730796352,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_PxT3DGYiI7pY9KXnfCSDHGpn',\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'truncation_strategy': {'type': 'auto', 'last_messages': None},\n",
       " 'usage': {'completion_tokens': 11, 'prompt_tokens': 68, 'total_tokens': 79},\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'tool_resources': {}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# espera de la ejecución y descripción\n",
    "\n",
    "run = esperar_ejecucion(run, thread)\n",
    "\n",
    "json.loads(run.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c5890",
   "metadata": {},
   "source": [
    "## 5 - Mensajes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387ac64",
   "metadata": {},
   "source": [
    "Ahora que la Ejecución (Run) ha finalizado, podemos listar los mensajes en el hilo para ver qué se ha agregado por el asistente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe08adf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sí, \\\\( x = 1 \\\\).'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vista de los mensajes y respuesta\n",
    "\n",
    "mensajes = cliente.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "json.loads(mensajes.model_dump_json())['data'][0]['content'][0]['text']['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27206628",
   "metadata": {},
   "source": [
    "Como podemos ver, los mensajes están ordenados en orden cronológico inverso. Esto se hizo para que los resultados más recientes siempre estén en la primera página, ya que los resultados pueden ser paginados. Tengamos esto en cuenta, ya que es el orden opuesto al de los mensajes en la API de Completaciones de Chat. Pidámosle a nuestro asistente que explique el resultado un poco más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeaccc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Claro, para encontrar \\\\( x \\\\), resta 11 de ambos lados para obtener \\\\( 3x = 3 \\\\), luego divide entre 3 para hallar \\\\( x = 1 \\\\).'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crea un mensaje para añadir al hilo\n",
    "mensaje = cliente.beta.threads.messages.create(thread_id=thread.id, \n",
    "                                               role='user', \n",
    "                                               content='¿Puedes explicarlo?')\n",
    "\n",
    "# ejecución\n",
    "run = cliente.beta.threads.runs.create(thread_id=thread.id, assistant_id=asistente.id)\n",
    "\n",
    "# esperar ejecución\n",
    "run = esperar_ejecucion(run, thread)\n",
    "\n",
    "# todos los mensajes\n",
    "mensajes = cliente.beta.threads.messages.list(thread_id=thread.id, order='asc', after=mensaje.id)\n",
    "\n",
    "\n",
    "mensajes.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089dfcf1",
   "metadata": {},
   "source": [
    "## 6 - Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d974f",
   "metadata": {},
   "source": [
    "Una característica clave de la API de asistentes es la capacidad de equipar a nuestros asistentes con herramientas, como el Code Interpreter, Retrieval (Recuperación) y funciones personalizadas. Echemos un vistazo a cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f9a54",
   "metadata": {},
   "source": [
    "### 6.1 - Code Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb08d8b",
   "metadata": {},
   "source": [
    "Equipemos a nuestro Tutor de Matemáticas con la herramienta [Code Interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter), lo cual podemos hacer desde el Dashboard o con código usando la API.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/assistants_overview_enable_code_interpreter.png\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ec1c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# añadimos code interpreter al asistente\n",
    "\n",
    "asistente = cliente.beta.assistants.update(assistant_id=asistente.id,\n",
    "                                           tools=[{'type': 'code_interpreter'}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75177efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_z9Eh9aRkMocFmM2wr0J8Y8x9',\n",
       " 'created_at': 1730796350,\n",
       " 'description': None,\n",
       " 'instructions': 'Eres un tutor personal de matemáticas. \\n                                                        Responde preguntas brevemente, en una frase o menos.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o',\n",
       " 'name': 'Tutor de matemáticas',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}],\n",
       " 'response_format': 'auto',\n",
       " 'temperature': 1.0,\n",
       " 'tool_resources': {'code_interpreter': {'file_ids': []}, 'file_search': None},\n",
       " 'top_p': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos su descripción\n",
    "\n",
    "json.loads(asistente.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75dc807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el hilo\n",
    "\n",
    "thread = cliente.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ea48317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora añadimos un mensaje al hilo\n",
    "\n",
    "usuario = 'Genera los 10 primeros números de la secuencia de Fibonacci con código.'\n",
    "\n",
    "mensaje = cliente.beta.threads.messages.create(thread_id=thread.id,\n",
    "                                               role='user',\n",
    "                                               content=usuario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6ffb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una ejecución\n",
    "\n",
    "run = cliente.beta.threads.runs.create(thread_id=thread.id,\n",
    "                                       assistant_id=asistente.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f093a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# espera de la ejecución \n",
    "\n",
    "run = esperar_ejecucion(run, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a0faa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Los 10 primeros números de la secuencia de Fibonacci son: 0, 1, 1, 2, 3, 5, 8, 13, 21 y 34.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vista de los mensajes y respuesta\n",
    "\n",
    "mensajes = cliente.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "mensajes.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becaf82c",
   "metadata": {},
   "source": [
    "### 6.2 - Steps (Pasos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0736d",
   "metadata": {},
   "source": [
    "Una Ejecución (Run) se compone de uno o más Pasos (Steps). Al igual que una ejecución, cada paso tiene un `status` (estado) que podemos consultar. Esto es útil para mostrar el progreso de un paso a un usuario, por ejemplo, un indicador de carga mientras el asistente está escribiendo código o realizando una recuperación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85049ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de pasos\n",
    "\n",
    "pasos = cliente.beta.threads.runs.steps.list(thread_id=thread.id, run_id=run.id, order='asc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f5cc7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"id\": \"call_wYD8o2TrbAd5FbmBlnqnC9c6\",\n",
      "            \"code_interpreter\": {\n",
      "                \"input\": \"# Generando los 10 primeros n\\u00fameros de la secuencia de Fibonacci\\ndef fibonacci_sequence(n):\\n    fib_seq = [0, 1]\\n    for i in range(2, n):\\n        fib_seq.append(fib_seq[-1] + fib_seq[-2])\\n    return fib_seq\\n\\n# Obtener los 10 primeros n\\u00fameros\\nfirst_10_fib_numbers = fibonacci_sequence(10)\\nfirst_10_fib_numbers\",\n",
      "                \"outputs\": []\n",
      "            },\n",
      "            \"type\": \"code_interpreter\"\n",
      "        }\n",
      "    ],\n",
      "    \"type\": \"tool_calls\"\n",
      "}\n",
      "{\n",
      "    \"message_creation\": {\n",
      "        \"message_id\": \"msg_TZpRBOKJwne5xNXcgiXX6gH3\"\n",
      "    },\n",
      "    \"type\": \"message_creation\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# detalle de cada paso\n",
    "\n",
    "for p in pasos.data:\n",
    "    \n",
    "    detalles = p.step_details\n",
    "    \n",
    "    print(json.dumps(json.loads(detalles.model_dump_json()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c7cf846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_TZpRBOKJwne5xNXcgiXX6gH3'), type='message_creation')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detalles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb59348",
   "metadata": {},
   "source": [
    "Podemos ver los detalles para dos pasos:\n",
    "\n",
    "1. `tool_calls`: Plural, ya que podría haber más de una en un solo paso, usando el code_interpreter.\n",
    "\n",
    "    + input: Código Python generado antes de que se llamara a la herramienta.\n",
    "    + output: Resultado de ejecutar el Code Interpreter.\n",
    "\n",
    "\n",
    "2. `message_creation`: Contiene el mensaje que se agregó al hilo para comunicar los resultados al usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2e546",
   "metadata": {},
   "source": [
    "### 6.3 - Retrieval (Recuperación)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a487e8",
   "metadata": {},
   "source": [
    "Otra herramienta poderosa en la API de asistentes es el [Retrieval](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval), la capacidad de cargar archivos que el asistente utilizará como una base de conocimiento al responder preguntas. Esto también se puede habilitar desde el Dashboard o la API, donde podemos cargar los archivos que queremos que se utilicen.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/assistants_overview_enable_retrieval.png\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a40aadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# añadimos file search al asistente\n",
    "\n",
    "asistente = cliente.beta.assistants.update(assistant_id=asistente.id,\n",
    "                                           tools=[{'type': 'file_search'}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf08f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar un archivo en el asistente\n",
    "\n",
    "ruta = '../../../files/language_models_are_unsupervised_multitask_learners.pdf'\n",
    "\n",
    "\n",
    "archivo = cliente.files.create(file=open(ruta, 'rb'),\n",
    "                               purpose='assistants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43d5559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el hilo y enviar mensaje\n",
    "\n",
    "mensaje = 'extrae 10 bullet points del libro.'\n",
    "\n",
    "config = [{'role': 'user', 'content': mensaje,\n",
    "           'attachments': [{ 'file_id': archivo.id, 'tools': [{'type': 'file_search'}]}]}]\n",
    "\n",
    "thread = cliente.beta.threads.create(messages=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62381a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una ejecución\n",
    "\n",
    "run = cliente.beta.threads.runs.create(thread_id=thread.id,\n",
    "                                       assistant_id=asistente.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9efc465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# espera de la ejecución \n",
    "\n",
    "run = esperar_ejecucion(run, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71df4f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puedo ayudar a extraer 10 puntos clave, pero necesito un poco más de información sobre el contenido del libro que deseas resumir o su estructura. ¿Podrías facilitarme ese detalle o indicarme una sección específica a analizar?\n"
     ]
    }
   ],
   "source": [
    "# vista de los mensajes y respuesta\n",
    "\n",
    "mensajes = cliente.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "print(mensajes.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947c07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "684.444px",
    "left": "109px",
    "top": "0px",
    "width": "335.992px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
