{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd31ed0",
   "metadata": {},
   "source": [
    "# 1 - Fine Tuning\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/openai_fine_tuning.webp\" style=\"width:400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3344e5",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---¿Qué-es-Fine-Tuning?\" data-toc-modified-id=\"1---¿Qué-es-Fine-Tuning?-1\">1 - ¿Qué es Fine Tuning?</a></span></li><li><span><a href=\"#2---Configuración\" data-toc-modified-id=\"2---Configuración-2\">2 - Configuración</a></span></li><li><span><a href=\"#3---Preparación-de-datos\" data-toc-modified-id=\"3---Preparación-de-datos-3\">3 - Preparación de datos</a></span></li><li><span><a href=\"#4---Subida-de-archivos\" data-toc-modified-id=\"4---Subida-de-archivos-4\">4 - Subida de archivos</a></span></li><li><span><a href=\"#5---Fine-Tuning\" data-toc-modified-id=\"5---Fine-Tuning-5\">5 - Fine Tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1---Status-Check\" data-toc-modified-id=\"5.1---Status-Check-5.1\">5.1 - Status Check</a></span></li></ul></li><li><span><a href=\"#6---Inferencia\" data-toc-modified-id=\"6---Inferencia-6\">6 - Inferencia</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f33e1d",
   "metadata": {},
   "source": [
    "## 1 - ¿Qué es Fine Tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f7985",
   "metadata": {},
   "source": [
    "El fine-tuning, o ajuste fino, es una técnica en el campo del aprendizaje automático que implica tomar un modelo previamente entrenado en una gran cantidad de datos generales y ajustarlo, reentrenarlo, con un conjunto de datos específico para una tarea particular. Esto permite que el modelo sea más preciso y eficaz en esa tarea específica sin tener que entrenar un modelo desde cero, lo cual puede ser costoso y llevar mucho tiempo. \n",
    "\n",
    "\n",
    "**Características del Fine-Tuning**\n",
    "\n",
    "\n",
    "1. **Uso de modelos preentrenados**: El fine-tuning comienza con un modelo que ya ha sido entrenado en una gran cantidad de datos generales. Estos modelos preentrenados ya han aprendido representaciones útiles y características básicas del lenguaje o imágenes, dependiendo del tipo de modelo.\n",
    "\n",
    "\n",
    "2. **Entrenamiento en datos específicos**: Después de tener el modelo preentrenado, se le reentrena, ajusta fino, con un conjunto de datos más pequeño y específico para la tarea en cuestión. Esto puede incluir datos específicos de un dominio, como textos médicos, datos financieros o cualquier otro tipo de información especializada.\n",
    "\n",
    "\n",
    "3. **Ajuste de parámetros**: Durante el fine-tuning, solo algunos de los parámetros del modelo pueden ser ajustados, mientras que otros se mantienen congelados, sin cambios. Esto ayuda a preservar el conocimiento general adquirido durante el preentrenamiento mientras se adapta a las especificidades del nuevo conjunto de datos.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Ventajas del Fine-Tuning**\n",
    "\n",
    "+ Eficiencia en tiempo y recursos. Es mucho más rápido y menos costoso ajustar un modelo preentrenado que entrenar uno desde cero.\n",
    "\n",
    "\n",
    "+ Mejora en la precisión. Permite que el modelo sea altamente preciso en tareas específicas gracias a la especialización proporcionada por los datos de ajuste fino.\n",
    "\n",
    "\n",
    "+ Flexibilidad. Puede ser aplicado a una amplia gama de tareas y dominios, haciendo que los modelos sean adaptables a diferentes necesidades.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Desafíos del Fine-Tuning**\n",
    "\n",
    "+ Sobrecarga de datos específicos. Existe el riesgo de que el modelo se ajuste demasiado a los datos específicos y pierda su capacidad de generalización.\n",
    "\n",
    "\n",
    "+ Necesidad de datos etiquetados. Requiere un conjunto de datos bien etiquetado y relevante para la tarea específica, lo cual puede ser difícil y costoso de obtener.\n",
    "\n",
    "\n",
    "+ Ajuste de hiperparámetros. Encontrar los hiperparámetros correctos (como la tasa de aprendizaje) para el ajuste fino puede ser complejo y requiere experimentación.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Proceso de Fine-Tuning**\n",
    "\n",
    "\n",
    "1. **Configuración**: Cargar nuestro conjunto de datos y filtrar para centrarse en un solo dominio para el ajuste fino.\n",
    "\n",
    "\n",
    "2. **Preparación de datos**: Preparar nuestros datos para el ajuste fino creando ejemplos de entrenamiento y validación, y subirlos al endpoint de Archivos.\n",
    "\n",
    "\n",
    "3. **Ajuste fino**: Crear nuestro modelo ajustado finamente.\n",
    "\n",
    "\n",
    "4. **Inferencia**: Usar nuestro modelo ajustado finamente para hacer inferencia en nuevas entradas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001533c9",
   "metadata": {},
   "source": [
    "## 2 - Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerías, API KEY e iniciamos cliente\n",
    "\n",
    "import os                           \n",
    "from dotenv import load_dotenv \n",
    "import openai as ai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "cliente = ai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daad6c9",
   "metadata": {},
   "source": [
    "El ajuste fino funciona mejor cuando se enfoca en un dominio particular. Es importante asegurarse de que nuestro conjunto de datos sea lo suficientemente específico para que el modelo pueda aprender, pero lo suficientemente general para que no se pierdan ejemplos no vistos. Teniendo esto en cuenta, hemos extraído un subconjunto del conjunto de datos RecipesNLG para que solo contenga documentos de [cookbooks](https://cookbooks.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81df45e",
   "metadata": {},
   "source": [
    "## 3 - Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0016895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga del csv\n",
    "\n",
    "data = pd.read_csv('../../files/cookbook_recipes_nlg_10k.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622f9a4",
   "metadata": {},
   "source": [
    "Comenzaremos preparando nuestros datos. Al ajustar finamente con el formato `ChatCompletion`, cada ejemplo de entrenamiento es una lista simple de mensajes. Por ejemplo, una entrada podría verse así:\n",
    "\n",
    "```python\n",
    "[{'role': 'system',\n",
    "  'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'},\n",
    "\n",
    " {'role': 'user',\n",
    "  'content': 'Title: No-Bake Nut Cookies\\n\\nIngredients: [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\\n\\nGeneric ingredients: '},\n",
    "\n",
    " {'role': 'assistant',\n",
    "  'content': '[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]'}]\n",
    "```\n",
    "\n",
    "Durante el proceso de entrenamiento, esta conversación se dividirá, con la última entrada siendo la finalización que el modelo producirá, y el resto de los mensajes actuando como el prompt. Tengamos en cuenta esto al construir nuestros ejemplos de entrenamiento: si nuestro modelo actuará en conversaciones de varios turnos, proporcionaremos ejemplos representativos para que no tenga un rendimiento deficiente cuando la conversación comience a expandirse.\n",
    "\n",
    "Actualmente hay un límite de 4096 tokens para cada ejemplo de entrenamiento. Cualquier cosa más larga que esto se truncará a 4096 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensaje_sistema = 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'\n",
    "\n",
    "\n",
    "def crear_mensaje_usuario(fila: object) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    Función para crear el mensaje del usuario.\n",
    "    \n",
    "    Params:\n",
    "    fila: fila de un pandas dataframe\n",
    "    \n",
    "    Return:\n",
    "    string \n",
    "    \"\"\"\n",
    "    \n",
    "    return f\"Title: {fila['title']}\\n\\nIngredients: {fila['ingredients']}\\n\\nGeneric ingredients: \"\n",
    "\n",
    "\n",
    "\n",
    "def preparar_ejemplo_conversacion(fila):\n",
    "    \n",
    "    \"\"\"\n",
    "    Función para perparar la conversacioncon el chat.\n",
    "    \n",
    "    Params:\n",
    "    fila: fila de un pandas dataframe\n",
    "    \n",
    "    Return:\n",
    "    dict \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return {'messages': [{'role': 'system', 'content': mensaje_sistema},\n",
    "                         {'role': 'user', 'content': crear_mensaje_usuario(fila)},\n",
    "                         {'role': 'assistant', 'content': fila['NER']}\n",
    "                        ]\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparar_ejemplo_conversacion(data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b453716",
   "metadata": {},
   "source": [
    "Ahora hagamos esto para un subconjunto del conjunto de datos que utilizaremos como datos de entrenamiento. Podemos comenzar con 30-50 ejemplos bien seleccionados. Deberíamos ver que el rendimiento continúa escalando linealmente a medida que aumentamos el tamaño del conjunto de entrenamiento, pero también tardarán más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usamos las primeras 100 filas para entrenar\n",
    "train_data = data.loc[0:100]\n",
    "\n",
    "# le aplicamos la preparacion de conversacion, pasamos a lista porque el objetivo es tener un json\n",
    "train_data = train_data.apply(preparar_ejemplo_conversacion, axis=1).tolist()\n",
    "\n",
    "for ejemplo in train_data[:5]:\n",
    "    print(ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c6841",
   "metadata": {},
   "source": [
    "Además de los datos de entrenamiento, también podemos proporcionar opcionalmente datos de validación, que se utilizarán para asegurarse de que el modelo no se sobreajuste al conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1781d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 filas de validacion\n",
    "val_data = data.loc[101:200]\n",
    "\n",
    "val_data = val_data.apply(preparar_ejemplo_conversacion, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f66b95",
   "metadata": {},
   "source": [
    "Ahora que tenemos listos los datos de entrenamiento y de validación, los guardamos en un archivo JSON, con extensión `.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def escribir_json(data: list, archivo: str) -> None:\n",
    "    \n",
    "    with open(archivo, 'w') as f:\n",
    "        \n",
    "        for d in data:\n",
    "            salida = json.dumps(d) + '\\n'\n",
    "            f.write(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68216c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardado de archivos\n",
    "\n",
    "escribir_json(train_data, 'recipe_finetune_train.jsonl')\n",
    "\n",
    "escribir_json(val_data, 'recipe_finetune_validacion.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422c391",
   "metadata": {},
   "source": [
    "## 4 - Subida de archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89c4a1",
   "metadata": {},
   "source": [
    "Una vez que tenemos los archivos de datos preparados, tenemos que subirlos al endpoint de OpanAI para ajustar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce377b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para subir archivos\n",
    "\n",
    "def subir_archivo(archivo: str, proposito: str = 'fine-tune') -> str:\n",
    "    \"\"\"\n",
    "    Esta funcion sube archivos a OpenAI\n",
    "    \n",
    "    Params:\n",
    "    archivo: string, ruta al archivo que queremos subir\n",
    "    proposito: string, proposito del archivo, en este caso fine-tune por defecto\n",
    "    \n",
    "    Return:\n",
    "    string con el ID del archivo\n",
    "    \"\"\"\n",
    "    \n",
    "    global cliente\n",
    "    \n",
    "    with open(archivo, 'rb') as f:\n",
    "        respuesta = cliente.files.create(file=f, purpose=proposito)\n",
    "        \n",
    "    return respuesta.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subida archivos\n",
    "\n",
    "train_id = subir_archivo('recipe_finetune_train.jsonl')\n",
    "\n",
    "val_id = subir_archivo('recipe_finetune_validacion.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training ID:', train_id)\n",
    "\n",
    "print('Validacion ID:', val_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61499c5",
   "metadata": {},
   "source": [
    "## 5 - Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c20f43",
   "metadata": {},
   "source": [
    "Ahora podemos crear nuestro trabajo de fine tuning con los archivos generados y un sufijo opcional para identificar el modelo. La respuesta contendrá un ID que podemos usar para obtener actualizaciones sobre el trabajo.\n",
    "\n",
    "Nota: Los archivos deben ser procesados primero por nuestro sistema, por lo que podríamos recibir un error de `File not ready` (\"Archivo no listo\"). En ese caso, simplemente lo intentaremos de nuevo unos minutos más tarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = cliente.fine_tuning.jobs.create(training_file=train_id,\n",
    "                                            validation_file=val_id,\n",
    "                                            model='gpt-4o-mini-2024-07-18',\n",
    "                                            suffix='recipe-ner')\n",
    "\n",
    "job_id = respuesta.id\n",
    "\n",
    "print('Job ID:', respuesta.id)\n",
    "print('Status:', respuesta.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c54df8",
   "metadata": {},
   "source": [
    "### 5.1 - Status Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21401ad0",
   "metadata": {},
   "source": [
    "Podemos hacer una solicitud `GET` al endpoint https://api.openai.com/v1/alpha/fine-tunes para listar nuestros trabajos de ajuste fino. En este caso, querremos verificar que el ID obtenido del paso anterior tenga el estado \"succeeded\".\n",
    "\n",
    "Una vez completado, podemos usar los archivos de resultado para muestrear los resultados del conjunto de validación y utilizar el ID del parámetro fine_tuned_model para invocar nuestro modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ca9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = cliente.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "\n",
    "print('Job ID:', respuesta.id)\n",
    "print('Status:', respuesta.status)\n",
    "print('Tokens Entrenados:', respuesta.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead3c07",
   "metadata": {},
   "source": [
    "Podemos hacer un seguimiento del progreso del ajuste fino con el endpoint de eventos. Podemos ejecutar la siguiente celda varias veces hasta que el ajuste fino esté listo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80118a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = cliente.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "eventos = respuesta.data\n",
    "eventos.reverse()\n",
    "\n",
    "for e in eventos:\n",
    "    print(e.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c8187",
   "metadata": {},
   "source": [
    "Una vez terminado, podemos obtener un ID de modelo ajustado a partir del trabajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88649d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = cliente.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "fine_tune_id = respuesta.fine_tuned_model\n",
    "\n",
    "\n",
    "if fine_tune_id is None:\n",
    "    \n",
    "    raise RuntimeError('ID no encontrado. El Fine Tuning no ha sido completado.')\n",
    "\n",
    "    \n",
    "print('ID Modelo Ajustado:', fine_tune_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8929146e",
   "metadata": {},
   "source": [
    "## 6 - Inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049337b3",
   "metadata": {},
   "source": [
    "El último paso es usar nuestro modelo ajustado para inferencia, simplemente llamamos a `ChatCompletions` con el nombre de nuestro nuevo modelo ajustado, completando el parámetro model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90982aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccion fila de testeo\n",
    "\n",
    "test_data = data.loc[201:300]\n",
    "\n",
    "test = test_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creacion de mensaje\n",
    "\n",
    "mensajes_test = []\n",
    "\n",
    "mensajes_test.append({'role': 'system', 'content': mensaje_sistema})\n",
    "\n",
    "mensaje_usuario = crear_mensaje_usuario(test)\n",
    "\n",
    "mensajes_test.append({'role': 'user', 'content': mensaje_usuario})\n",
    "\n",
    "print(mensajes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db203949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# respuesta del modelo\n",
    "\n",
    "respuesta = cliente.chat.completions.create(model=fine_tune_id, \n",
    "                                            messages=mensajes_test, \n",
    "                                            temperature=0, \n",
    "                                            max_tokens=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respuesta.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43caae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "684.436px",
    "left": "114px",
    "top": "180px",
    "width": "335.99px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
