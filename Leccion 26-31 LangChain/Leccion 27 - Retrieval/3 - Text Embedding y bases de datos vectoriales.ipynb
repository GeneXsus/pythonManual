{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0bd0f0b",
   "metadata": {},
   "source": [
    "# 3 - Text Embedding y bases de datos vectoriales\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/langchain.jpeg\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191be87",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---Modelos-de-Text-Embedding\" data-toc-modified-id=\"1---Modelos-de-Text-Embedding-1\">1 - Modelos de Text Embedding</a></span></li><li><span><a href=\"#2---Bases-de-datos-vectoriales\" data-toc-modified-id=\"2---Bases-de-datos-vectoriales-2\">2 - Bases de datos vectoriales</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a17ad4",
   "metadata": {},
   "source": [
    "## 1 - Modelos de Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebaa12a",
   "metadata": {},
   "source": [
    "Los modelos de text embedding en LangChain proporcionan una interfaz estandarizada para varios proveedores de modelos de embedding, como OpenAI o Hugging Face. Estos modelos transforman el texto en representaciones vectoriales, lo que permite realizar operaciones como la búsqueda semántica a través de la similitud de texto en el espacio vectorial. En LangChain, el método embed_documents se utiliza para incrustar múltiples textos, proporcionando una lista de representaciones vectoriales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e27b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings de OpenAI\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8246ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero cargamos la API KEY de OpenAI\n",
    "\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "\n",
    "# carga de variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# api key openai, nombre que tiene por defecto en LangChain\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63a4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos modelo, text-embedding-ada-002 por defecto\n",
    "\n",
    "modelo = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60cf1feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista de textos\n",
    "\n",
    "textos = ['¡Hola!', '¡Oh, hola!', '¿Cómo te llamas?', 'Mis amigos me llaman Mundo', '¡Hola Mundo!']\n",
    "\n",
    "len(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa785ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings desde una lista de textos\n",
    "\n",
    "embeddings = modelo.embed_documents(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dca9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nº de vectores\n",
    "\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce66fee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensiones de cada vector\n",
    "\n",
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ed475",
   "metadata": {},
   "source": [
    "Para realizar el embedding un solo texto, como una consulta de búsqueda, se utiliza el método embed_query. Esto es útil para comparar una consulta con un conjunto de incrustaciones de documentos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b67bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = modelo.embed_query('Hola que tal estas?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f139d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensiones del vector\n",
    "\n",
    "len(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ac2a1",
   "metadata": {},
   "source": [
    "Comprender estos embeddings es crucial. Cada fragmento de texto se convierte en un vector, cuya dimensión depende del modelo utilizado. Por ejemplo, los modelos de OpenAI suelen producir vectores de 1536 dimensiones. Estos embeddings se utilizan luego para recuperar información relevante.\n",
    "\n",
    "La funcionalidad de embeddings de LangChain no se limita a OpenAI, sino que está diseñada para trabajar con varios proveedores. La configuración y el uso pueden variar ligeramente según el proveedor, pero el concepto básico de text embedding en el espacio vectorial sigue siendo el mismo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b013038",
   "metadata": {},
   "source": [
    "## 2 - Bases de datos vectoriales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0326b1f",
   "metadata": {},
   "source": [
    "Las bases de datos vectoriales en LangChain admiten el almacenamiento y la búsqueda eficiente de embeddings de texto. LangChain se integra con más de 50 bases de datos vectoriales, proporcionando una interfaz estandarizada para facilitar su uso. Vamos a usar `Chroma` para guardar los embeddings y realizar consultas segun la similitud de esos vectores. Para usarla tendremos que ejecutar el siguiente comando:\n",
    "\n",
    "```bash\n",
    "pip install chromadb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b244e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa72d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creacion de la base de datos\n",
    "\n",
    "db = Chroma.from_texts(texts=textos,                 # lista de textos a guardar\n",
    "                       embedding=OpenAIEmbeddings(), # funcion de embedding\n",
    "                       persist_directory= './',      # ruta guardado de la base de datos\n",
    "                       collection_name='prueba'      # nombre de la coleccion\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "008cec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='¡Hola!'),\n",
       " Document(metadata={}, page_content='¡Hola Mundo!'),\n",
       " Document(metadata={}, page_content='¡Oh, hola!')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consulta\n",
    "\n",
    "db.similarity_search(query='hola',   # consulta de usuario \n",
    "                     k=3,            # k documentos mas parecidos\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
