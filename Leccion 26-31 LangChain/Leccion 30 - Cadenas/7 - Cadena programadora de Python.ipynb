{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef70934",
   "metadata": {},
   "source": [
    "# 7 - Cadena programadora de Python\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/langchain.jpeg\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4f8b4",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---Cadena-programadora-de-Python\" data-toc-modified-id=\"1---Cadena-programadora-de-Python-1\">1 - Cadena programadora de Python</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abb010",
   "metadata": {},
   "source": [
    "## 1 - Cadena programadora de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9554c",
   "metadata": {},
   "source": [
    "Una de las aplicaciones más poderosas del LCEL es escribir código Python para resolver problemas de los usuarios. Vamos a ver un ejemplo donde un usuario proporciona una entrada y LCEL genera código Python para resolver el problema. Luego, el código se ejecuta utilizando un REPL de Python y el código Python resultante se devuelve en formato Markdown. Hay que tener en cuenta que el uso de un REPL de Python puede ejecutar código arbitrario, por lo que debe usarse con precaución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce45d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos la API KEY de OpenAI\n",
    "\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "\n",
    "# carga de variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# api key openai, nombre que tiene por defecto en LangChain\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8798d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerias\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab3186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el modelo de OpenAI\n",
    "\n",
    "modelo = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494877b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser de salida, transforma la salida a string\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bad905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el prompt\n",
    "\n",
    "plantilla = '''Write some python code to solve the user's problem.\n",
    "               \n",
    "               Return only python code in Markdown format, e.g.:\n",
    "\n",
    "               ```python\n",
    "               ....\n",
    "               ```\n",
    "               '''\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([('system', plantilla), ('human', '{pregunta}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9ef168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambio de la string de salida\n",
    "\n",
    "def limpiar_salida(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Esta funcion limpia la salida del modelo.\n",
    "    El modelo devolvera markdown y esta funcion \n",
    "    devolvera el codigo en formato string\n",
    "    \n",
    "    Params:\n",
    "    texto: str, formato markdown\n",
    "    \n",
    "    Return:\n",
    "    codigo en formato string\n",
    "    \"\"\"\n",
    "    \n",
    "    texto = texto.split('```python')[1].replace('```', '')\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf9cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de la cadena\n",
    "\n",
    "cadena = prompt | modelo | parser | limpiar_salida | PythonREPL().run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e3063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# respuesta de la cadena\n",
    "\n",
    "respuesta = cadena.invoke({'pregunta' :'cuanto es 2 y 2'})\n",
    "\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e98eaf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# respuesta de la cadena\n",
    "\n",
    "respuesta = cadena.invoke({'pregunta' :'8 factorial'})\n",
    "\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b975d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
