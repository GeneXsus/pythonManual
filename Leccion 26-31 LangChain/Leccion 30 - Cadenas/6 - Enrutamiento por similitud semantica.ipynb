{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a104164c",
   "metadata": {},
   "source": [
    "# 6 - Enrutamiento por similitud semántica\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hack-io-AI/ai_images/main/langchain.jpeg\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66af6e9",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1---Enrutamiento-por-similitud-semántica\" data-toc-modified-id=\"1---Enrutamiento-por-similitud-semántica-1\">1 - Enrutamiento por similitud semántica</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede21f76",
   "metadata": {},
   "source": [
    "## 1 - Enrutamiento por similitud semántica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03164d",
   "metadata": {},
   "source": [
    "LCEL nos permite implementar lógica de enrutamiento personalizada basada en la similitud semántica de la entrada del usuario. Veamos un ejemplo de cómo determinar dinámicamente la lógica de la cadena según la entrada del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c9414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos la API KEY de OpenAI\n",
    "\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "\n",
    "# carga de variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# api key openai, nombre que tiene por defecto en LangChain\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d25d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerias\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "from langchain.utils.math import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40b085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el modelo de OpenAI\n",
    "\n",
    "modelo = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0629c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser de salida, transforma la salida a string\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0907f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el primer prompt\n",
    "\n",
    "plantilla_fisica = '''Eres un profesor de física muy inteligente.\n",
    "                      Eres excelente respondiendo preguntas sobre física de \n",
    "                      manera concisa y fácil de entender.\n",
    "                      Cuando no sabes la respuesta a una pregunta, admites que no la sabes.\n",
    "                      \n",
    "                      Aquí tienes una pregunta:\n",
    "                      {pregunta}\n",
    "                      \n",
    "                    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ead5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el segundo prompt\n",
    "\n",
    "plantilla_matematicas = '''Eres un muy buen matemático. \n",
    "                           Eres excelente respondiendo preguntas de matemáticas.\n",
    "                           Eres tan bueno porque puedes descomponer problemas difíciles \n",
    "                           en sus partes componentes, responder esas partes y \n",
    "                           luego juntarlas para responder la pregunta más amplia.\n",
    "                           \n",
    "                           Aquí tienes una pregunta:\n",
    "                           {pregunta}\n",
    "                        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "590dc6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# los ponemos en una lista para usarlos despues\n",
    "\n",
    "plantillas = [plantilla_fisica, plantilla_matematicas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e59d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciamos el modelo de embedding\n",
    "\n",
    "modelo_embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4629c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizamos la vectorizacion de los prompts\n",
    "\n",
    "prompt_embeddings = modelo_embeddings.embed_documents(plantillas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f609e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longitud del vector de embedding\n",
    "\n",
    "len(prompt_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb8dbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para enrutar el prompt\n",
    "\n",
    "def enrutador_prompt(usuario: dict) -> PromptTemplate.from_template:\n",
    "    \n",
    "    \"\"\"\n",
    "    Esta función decide el comportamiento del modelo segun \n",
    "    la pregunta del usuario. Compara la similitud entre la pregunta realizada\n",
    "    y los prompts de matematicas o fisica y decide cual de ellos usar.\n",
    "    \n",
    "    Params:\n",
    "    usuario: dict, diccionario con la key 'pregunta'\n",
    "    \n",
    "    Return:\n",
    "    objeto PromptTemplate.from_template para ser pasado a la cadena\n",
    "    \"\"\"\n",
    "    \n",
    "    global modelo_embeddings, prompt_embeddings, plantillas\n",
    "\n",
    "    embedding_pregunta = modelo_embeddings.embed_query(usuario['pregunta'])\n",
    "    \n",
    "    similitud = cosine_similarity([embedding_pregunta], prompt_embeddings)[0]\n",
    "    \n",
    "    mas_similar = plantillas[similitud.argmax()]\n",
    "    \n",
    "    print('Usando MATEMATICAS' if mas_similar == plantilla_matematicas else 'Usando FISICA')\n",
    "    \n",
    "    return PromptTemplate.from_template(mas_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87dbb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la cadena\n",
    "\n",
    "cadena = RunnableLambda(enrutador_prompt) | modelo | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f30d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando FISICA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Un agujero negro es una región del espacio donde la gravedad es tan intensa que nada, ni siquiera la luz, puede escapar de su atracción. Se forma cuando una estrella masiva colapsa sobre sí misma y su núcleo se comprime tanto que crea un campo gravitacional extremadamente fuerte. Todo lo que cae dentro de un agujero negro es absorbido por él, creando una región de la cual nada puede salir. Los agujeros negros son objetos fascinantes y aún hay mucho por descubrir sobre ellos en el campo de la física.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respuesta de la cadena\n",
    "\n",
    "cadena.invoke({'pregunta': 'qué es un agujero negro'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856e100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando MATEMATICAS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Una integral de caminos es un concepto utilizado en el campo de la teoría de la probabilidad y en la física cuántica. Se refiere a la integral de una función a lo largo de todos los posibles caminos o trayectorias que puede seguir una partícula desde un punto A hasta un punto B en un espacio determinado. En lugar de calcular la integral a lo largo de una única trayectoria específica, se consideran todas las posibles trayectorias y se suman sus contribuciones. Este enfoque se utiliza en situaciones donde el comportamiento de una partícula no puede ser descrito de manera determinista, sino que se rige por la probabilidad. La integral de caminos es una herramienta matemática poderosa que se utiliza para modelar sistemas complejos y estudiar fenómenos cuánticos.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respuesta de la cadena\n",
    "\n",
    "cadena.invoke({'pregunta': 'qué es una integral de caminos'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5dd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
